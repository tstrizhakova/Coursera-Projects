{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21a810ee",
   "metadata": {},
   "source": [
    "## Классификация текстов: спам-фильтр для SMS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a13c424",
   "metadata": {},
   "source": [
    "В этом задании мы возьмем открытый датасет с SMS-сообщениями, размеченными на спам (\"spam\") и не спам (\"ham\"), построим на нем классификатор текстов на эти два класса, оценим его качество с помощью кросс-валидации, протестируем его работу на отдельных примерах, и посмотрим, что будет происходить с качеством, если менять параметры модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c5bca331",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6690deb6",
   "metadata": {},
   "source": [
    "Загрузим датасет и подготовим два списка:\n",
    "* список текстов в порядке их следования в датасете\n",
    "* список соответствующих им меток классов.\n",
    "\n",
    "В качестве метки класса используем 1 для спама и 0 для \"не спама\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d3c1a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SMSSpamCollection.txt', 'r', encoding='utf-8') as file:\n",
    "    sms = file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de9a518c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ham\\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...',\n",
       " 'ham\\tOk lar... Joking wif u oni...',\n",
       " \"spam\\tFree entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\",\n",
       " 'ham\\tU dun say so early hor... U c already then say...',\n",
       " \"ham\\tNah I don't think he goes to usf, he lives around here though\"]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "78c840c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_labels, sms_text = zip(*[line.split('\\t') for line in sms])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8dc5388d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.array([0 if word == 'ham' else 1 for word in sms_labels])\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d245a2",
   "metadata": {},
   "source": [
    "Создадим из списка текстов матрицу признаков Х и оценим качество классификации текстов с помощью LogisticRegression()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f2f6b61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_pipeline = Pipeline(\n",
    "            [('vectorizer', CountVectorizer()),\n",
    "            ('regression', LogisticRegression())])\n",
    "\n",
    "\n",
    "score = cross_val_score(clf_pipeline, sms_text, labels, scoring='f1', cv=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2600c466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross_val_score f1: 0.9311\n"
     ]
    }
   ],
   "source": [
    "print('Cross_val_score f1: %.4f' % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9f9298",
   "metadata": {},
   "source": [
    "Теперь обучим классификатор на всей выборке и спрогнозируем с его помощью класс для следующих сообщений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bd660cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = ['FreeMsg: Txt: CALL to No: 86888 & claim your reward of 3 hours talk time to use from your phone now! Subscribe6GB',\n",
    "            'FreeMsg: Txt: claim your reward of 3 hours talk time',\n",
    "            'Have you visited the last lecture on physics?',\n",
    "            'Have you visited the last lecture on physics? Just buy this book and you will have all materials! Only 99$',\n",
    "            'Only 99$']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "98f212cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', CountVectorizer()),\n",
       "                ('regression', LogisticRegression())])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_pipeline.fit(sms_text, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2810af6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_pipeline.predict(test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a386a857",
   "metadata": {},
   "source": [
    "Зададим в CountVectorizer три разных параметра ngram_range. Во всех случаях измерим получившееся в кросс-валидации значение f1-меры. В данном эксперименте мы пробовали добавлять в признаки n-граммы для разных диапазонов n - только биграммы, только триграммы, и, наконец, все вместе - униграммы, биграммы и триграммы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9f48d81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ngram_range:  (2, 2)\n",
      "Cross-val-score f1: 0.8168\n",
      "\n",
      "Ngram_range:  (3, 3)\n",
      "Cross-val-score f1: 0.7250\n",
      "\n",
      "Ngram_range:  (1, 3)\n",
      "Cross-val-score f1: 0.9223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ngram_range = [(2, 2), (3, 3), (1, 3)]\n",
    "scores = []\n",
    "for n in ngram_range:\n",
    "    clf_pipeline = Pipeline(\n",
    "            [('vectorizer', CountVectorizer(ngram_range=n)),\n",
    "            ('regression', LogisticRegression())])\n",
    "    score = cross_val_score(clf_pipeline, sms_text, labels, scoring='f1', cv=10).mean()\n",
    "    scores.append(score)\n",
    "    print('Ngram_range: ', n)\n",
    "    print('Cross-val-score f1: %.4f\\n' % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fb8f27",
   "metadata": {},
   "source": [
    "Повторим аналогичный эксперимент, используя вместо логистической регрессии MultinomialNB()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c415c732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ngram_range:  (2, 2)\n",
      "Cross-val-score f1: 0.6451\n",
      "\n",
      "Ngram_range:  (3, 3)\n",
      "Cross-val-score f1: 0.3786\n",
      "\n",
      "Ngram_range:  (1, 3)\n",
      "Cross-val-score f1: 0.8878\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for ngram in ngram_range:\n",
    "    X_counts = CountVectorizer(ngram_range=ngram).fit_transform(sms_text)\n",
    "    bayes = MultinomialNB()\n",
    "    score = cross_val_score(bayes, X_counts, labels, scoring='f1', cv=10).mean()\n",
    "    scores.append(score)\n",
    "    print('Ngram_range: ', ngram)\n",
    "    print('Cross-val-score f1: %.4f\\n' % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d559dc1e",
   "metadata": {},
   "source": [
    "Попробуем использовать в логистической регрессии в качестве признаков Tf*idf из TfidfVectorizer на униграммах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c9d32fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.878423460536647"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_pipeline = Pipeline(\n",
    "            [('vectorizer', TfidfVectorizer()),\n",
    "            ('regression', LogisticRegression())])\n",
    "score = cross_val_score(clf_pipeline, sms_text, labels, scoring='f1', cv=10).mean()\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89102928",
   "metadata": {},
   "source": [
    "Как мы видим, качество на кросс-валидации по сравнению с CountVectorizer на униграммах заметно понизилось."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f39e95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
